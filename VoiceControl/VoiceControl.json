{
    "$schema": "https://raw.githubusercontent.com/rdkcentral/rdkservices/main/Tools/json_generator/schemas/interface.schema.json",
    "jsonrpc": "2.0",
    "info": {
        "title": "VoiceControl API",
        "class": "VoiceControl",
        "description": "The `VoiceControl` plugin manages voice control sessions."
    },
    "common": {
        "$ref": "../common/common.json"
    },
    "definitions": {
        "maskPii": {
            "summary": "Indicated is PII should be masked (1 - mask PII, 0 display PII",
            "type": "boolean",
            "example": true
        },
        "capabilities": {
            "summary": "A list of capabilities",
            "type": "array",
            "items": {
                "type": "string",
                "example": "PRV"
            }
        },
        "urlPtt": {
            "summary": "The PTT URL",
            "type": "string",
            "example": "vrng://vrex-next-gen-api.vrexcore.net/vrex/speech/websocket"
        },
        "urlHf": {
            "summary": "The HF (ff and mic) URL",
            "type": "string",
            "example": "ws://voiceserver.com/voice/hf"
        },
        "urlMicTap": {
            "summary": "The microphone tap URL",
            "type": "string",
            "example": "ws://voiceserver.com/voice/mictap"
        },
        "prv": {
            "summary": "The Press & Release Voice feature. `true` for enable, `false` for disable",
            "type": "boolean",
            "example": true
        },
        "wwFeedback": {
            "summary": "The Wake Word Feedback feature (typically an audible beep). `true` for enable, `false` for disable",
            "type": "boolean",
            "example": false
        },
        "status": {
            "summary": "The status of the device",
            "type": "string",
            "example": "ready"
        },
        "enable": {
            "summary": "Enable (`true`) or disable (`false`)",
            "type": "boolean",
            "example": false
        },
        "remoteId": {
            "summary": "The voice device identifier",
            "type": "integer",
            "example": 1
        },
        "sessionId": {
            "summary": "The unique identifier for the voice session, generated by the underlying RDK stack",
            "type": "string",
            "example": "1b11359e-23fe-4f2f-9ba8-cc19b87203cf"
        },
        "requestTypes": {
            "summary": "If successful, an array of strings indicating the voice session request types which are valid",
            "type": "array",
            "items": {
                "type": "string",
                "example": "ptt_transcription"
            }
        }
    },
    "methods": {
        "configureVoice": {
            "summary": "Configures the RDK's voice stack. NOTE: The URL Scheme determines which API protocol is used. Supported URL schemes include:\n\n| Scheme | Description |\n| :-------- | :-------- |\n| http/https | VREX Legacy HTTP API |\n| ws/wss | VREX XR18 WS API |\n| vrng/vrngs | VREX NextGen WS API |\n| aows/aowss | Audio only over websockets with no protocol layer |\n| sdt | Simple data transfer for direct handling of audio in the protocol layer |",
            "params": {
                "type": "object",
                "properties": {
                    "urlAll": {
                        "summary": "Specifies the URL for all devices instead of individually specifying the URL for each device",
                        "type": "string",
                        "example": "ws://voiceserver.com/voice/ptt"
                    },
                    "urlPtt": {
                        "$ref": "#/definitions/urlPtt"
                    },
                    "urlHf": {
                        "$ref": "#/definitions/urlHf"
                    },
                    "urlMicTap": {
                        "$ref": "#/definitions/urlMicTap"
                    },
                    "enable": {
                        "summary": "Enables or disables all of the voice devices instead of individually enabling or disabling each device",
                        "type": "boolean",
                        "example": true
                    },
                    "prv": {
                        "$ref": "#/definitions/prv"
                    },
                    "wwFeedback": {
                        "$ref": "#/definitions/wwFeedback"
                    },
                    "ptt": {
                        "summary": "The settings for PTT devices",
                        "type": "object",
                        "properties": {
                            "enable": {
                                "$ref": "#/definitions/enable"
                            }
                        }
                    },
                    "ff": {
                        "summary": "The settings for FF devices",
                        "type": "object",
                        "properties": {
                            "enable": {
                                "$ref": "#/definitions/enable"
                            }
                        }
                    },
                    "mic": {
                        "summary": "The settings for MIC devices",
                        "type": "object",
                        "properties": {
                            "enable": {
                                "$ref": "#/definitions/enable"
                            }
                        }
                    }
                },
                "required": [ ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "sendVoiceMessage": {
            "summary": "Sends a message to the Voice Server. The specification of this message is not in the scope of this document. Example use cases for this API call include sending context or sending ASR blobs to the server.",
            "params":{
                "type": "object",
                "properties": {
                    "msgType": {
                        "summary":"msg type expected from server",
                        "type": "string",
                        "example": "ars"
                    },
                    "trx": {
                        "summary":"The unique id of the voice session",
                        "type": "string",
                        "example": "1b11359e-23fe-4f2f-9ba8-cc19b87203cf"
                    },
                    "created": {
                        "summary":"The timestamp for server information",
                        "type": "number",
                        "example": 91890278389232
                    },
                    "msgPayload":{
                        "summary":"NA",
                        "type": "object",
                        "properties": {

                        }
                    }
                },
                "required": [ ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "setVoiceInit": {
            "summary": "Sets the application metadata in the INIT message that gets sent to the Voice Server. The specification of this blob is not in the scope of this document, but it MUST be a JSON blob.",
            "params": {
                "type":"object",
                "properties": {
                    "capabilities": {
                        "$ref": "#/definitions/capabilities"
                    },
                    "language": {
                        "summary":"Preferred user interface language",
                        "type": "string",
                        "example": "eng-USA"
                    }
                },
                "required": [ ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "voiceSessionByText": {
            "summary": "Sends a voice session with a transcription string to simulate a real voice session for QA. Example use cases for this API call include rack and automation testing.",
            "events":{
                "onSessionBegin" : "Triggers if the voice session begins",
                "onStreamBegin" : "Triggers if a device starts streaming voice data to the RDK",
                "onServerMessage" : "Triggers if a message is received from the Voice Server",
                "onStreamEnd" : "Triggers if streaming audio is stopped from the device",
                "onSessionEnd" : "Triggers if interaction with the server is end"
            },
            "params":{
                "type": "object",
                "properties": {
                    "transcription": {
                        "summary": "The transcription text to be sent to the voice server",
                        "type": "string",
                        "example": "Watch Comedy Central"
                    },
                    "type": {
                        "summary": "The device type to simulate the voice session from (PTT, FF, MIC)",
                        "type": "string",
                        "example": "PTT"
                    }
                },
                "required": [
                    "transcription"
                ]
            },
            "result": {
                "$ref": "#/common/result"
            },
            "deprecated": true,
            "referenceUrl": "https://rdkcentral.github.io/rdkservices/#/api/VoiceControlPlugin?id=voicesessionrequest"
        },
        "voiceSessionTypes": {
            "summary": "Retrieves the types of voice sessions which are supported by the platform.\n\n| Request Type | Description |\n| :-------- | :-------- |\n| ptt_transcription | A text-only session using the urlPtt routing url and the text transcription |\n| ptt_audio_file | A session using the urlPtt routing url and the specified audio file |\n| mic_transcription | A text-only session using the urlHf routing url and the text transcription |\n| mic_audio_file | A session using the urlHf routing url and the specified audio file |\n| mic_stream_default | An audio based session using the urlHf routing url and the platform's default audio output format |\n| mic_stream_single | An audio based session using the urlHf routing url and the platform's single channel audio input format |\n| mic_stream_multi | An audio based session using the urlHf routing url and the platform's multi-channel audio input format |\n| mic_tap_stream_single | An audio based session using the urlMicTap routing url and the platform's single channel audio input format |\n| mic_tap_stream_multi | An audio based session using the urlMicTap routing url and the platform's multi-channel audio input format |\n| mic_factory_test | An audio based session using the urlHf routing url and the platform's unprocessed multi-channel audio input format |",
            "result": {
                "type": "object",
                "properties": {
                    "types": {
                        "$ref": "#/definitions/requestTypes"
                    },
                    "success": {
                        "$ref": "#/common/success"
                    }
                },
                "required":[
                    "success"
                ]
            }
        },
        "voiceSessionRequest": {
            "summary": "Requests a voice session using the specified request type and optional parameters.",
            "events":{
                "onSessionBegin" : "Triggers if the voice session begins",
                "onStreamBegin" : "Triggers if a device starts streaming voice data to the RDK",
                "onServerMessage" : "Triggers if a message is received from the Voice Server",
                "onStreamEnd" : "Triggers if streaming audio is stopped from the device",
                "onSessionEnd" : "Triggers if interaction with the server is end"
            },
            "params":{
                "type": "object",
                "properties": {
                    "transcription": {
                        "summary": "The transcription text to be sent to the voice server for request types \"ptt_transcription\" and \"mic_transcription\".",
                        "type": "string",
                        "example": "Watch Comedy Central"
                    },
                    "audio_file": {
                        "summary": "The full path to the audio file to be sent to the voice server for request types \"ptt_audio_file\" and \"mic_audio_file\".",
                        "type": "string",
                        "example": "/opt/audio_file.wav"
                    },
                    "name": {
                        "summary": "The name of the application requesting the voice session.",
                        "type": "string",
                        "example": "Application"
                    },
                    "type": {
                        "summary": "The request type to initiate the voice session (see [voiceSessionTypes](#method.voiceSessionTypes) API for list of request types)",
                        "type": "string",
                        "example": "ptt_transcription"
                    }
                },
                "required": [
                    "type"
                ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "voiceSessionTerminate": {
            "summary": "Terminates a voice session using the specified session identifier.",
            "params":{
                "type": "object",
                "properties": {
                    "sessionId": {
                        "summary": "The session identifier of the session from the [onSessionBegin](#event.onSessionBegin) event",
                        "type": "string",
                        "example": "1b11359e-23fe-4f2f-9ba8-cc19b87203cf"
                    }
                },
                "required": [
                    "sessionId"
                ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "voiceSessionAudioStreamStart": {
            "summary": "Starts a subsequent audio stream for the voice session indicated by the session identifier.",
            "params":{
                "type": "object",
                "properties": {
                    "sessionId": {
                        "summary": "The session identifier of the session from the [onSessionBegin](#event.onSessionBegin) event",
                        "type": "string",
                        "example": "1b11359e-23fe-4f2f-9ba8-cc19b87203cf"
                    }
                },
                "required": [
                    "sessionId"
                ]
            },
            "result": {
                "$ref": "#/common/result"
            }
        },
        "voiceStatus": {
            "summary": "Returns the current status of the RDK voice stack. This includes which URLs the stack is currently configured for along with the status for each device type.",
            "result": {
                "type": "object",
                "properties": {
                    "maskPii": {
                        "$ref": "#/definitions/maskPii"
                    },
                    "capabilities": {
                        "$ref": "#/definitions/capabilities"
                    },
                    "urlPtt": {
                        "$ref": "#/definitions/urlPtt"
                    },
                    "urlHf": {
                        "$ref": "#/definitions/urlHf"
                    },
                    "prv": {
                        "$ref": "#/definitions/prv"
                    },
                    "wwFeedback": {
                        "$ref": "#/definitions/wwFeedback"
                    },
                    "ptt": {
                        "summary": "The status information for the PTT device type",
                        "type": "object",
                        "properties": {
                            "status": {
                                "$ref": "#/definitions/status"
                            }
                        },
                        "required": [
                            "status"
                        ]
                    },
                    "ff": {
                        "summary": "The status information for the FF device type",
                        "type": "object",
                        "properties": {
                            "status": {
                                "$ref": "#/definitions/status"
                            }
                        },
                        "required": [
                            "status"
                        ]
                    },
                    "mic": {
                        "summary": "The status information for the MIC device type",
                        "type": "object",
                        "properties": {
                            "status": {
                                "$ref": "#/definitions/status"
                            }
                        },
                        "required": [
                            "status"
                        ]
                    },
                    "success": {
                        "$ref": "#/common/success"
                    }
                },
                "required":[
                    "capabilities",
                    "urlPtt",
                    "urlHf",
                    "prv",
                    "wwFeedback",
                    "ptt",
                    "ff",
                    "mic",
                    "success"
                ]
            }
        }
    },
    "events": {
        "onKeywordVerification": {
            "summary": "Triggered when a keyword verification result is received",
            "params": {
                "type": "object",
                "properties": {
                    "remoteId": {
                        "$ref": "#/definitions/remoteId"
                    },
                    "sessionId": {
                        "$ref": "#/definitions/sessionId"
                    },
                    "verified": {
                        "summary": "`true` if the keyword was verified, otherwise `false`",
                        "type": "boolean",
                        "example": true
                    }
                },
                "required": [
                    "remoteId",
                    "sessionId",
                    "verified"
                ]
            }
        },
        "onServerMessage": {
            "summary": "Triggered when a message is received from the Voice Server. The `params` value is a contract between the Voice Server and the Application. The definition of this object is outside of the scope of this document.",
            "params":{
                "type": "object",
                "properties": {
                    "msgType": {
                        "summary": "Message type from the server",
                        "type": "string",
                        "example": "ars"
                    },
                    "trx": {
                        "summary":"The unique id of the voice session",
                        "type": "string",
                        "example": "1b11359e-23fe-4f2f-9ba8-cc19b87203cf"
                    },
                    "created": {
                        "summary":"The timestamp for server information",
                        "type": "number",
                        "example": 91890278389232
                    },
                    "msgPayload":{
                        "summary":"Vrex server information",
                        "type": "object",
                        "properties": {

                        }
                    }
                },
                "required": [
                    "msgType",
                    "trx",
                    "created",
                    "msgPayload"
                ]
            }
        },
        "onSessionBegin": {
            "summary": "Triggered when a voice session begins",
            "params": {
                "type": "object",
                "properties": {
                    "remoteId": {
                        "$ref": "#/definitions/remoteId"
                    },
                    "sessionId": {
                        "$ref": "#/definitions/sessionId"
                    },
                    "deviceType": {
                        "summary": "The type of voice device starting the session",
                        "type": "string",
                        "enum": [
                            "ptt",
                            "ff",
                            "mic"
                        ],
                        "example": "ptt"
                    },
                    "keywordVerification": {
                        "summary": "`true` if the session uses keyword verification, otherwise `false`",
                        "type": "boolean",
                        "example": true
                    }
                },
                "required": [
                    "remoteId",
                    "sessionId",
                    "deviceType",
                    "keywordVerification"
                ]
            }
        },
        "onSessionEnd": {
            "summary": "Triggered when the interaction with the server has concluded",
            "params": {
                "type": "object",
                "properties": {
                    "serverStats":{
                        "summary":"Returns the voice server stats",
                        "type":"object",
                        "properties": {
                            "dnsTime":{
                                "summary":"The DNS time of the voice server",
                                "type":"number",
                                "example": 1.0
                            },
                            "serverIp" :{
                                "summary":"The ip of the voice server",
                                "type":"string",
                                "example": ""
                            },
                            "connectTime":{
                                "summary":"The connection time of the voice server",
                                "type":"number",
                                "example": 1.0
                            }
                        },
                        "required":[
                            "dnsTime",
                            "serverIp",
                            "connectTime"
                        ]
                    },
                    "remoteId": {
                        "$ref": "#/definitions/remoteId"
                    },
                    "sessionId": {
                        "$ref": "#/definitions/sessionId"
                    },
                    "result": {
                        "summary": "The result of the voice session. This also determines which object will be in the parameters (`success`, `error`, `abort`, `shortUtterance`).",
                        "type": "string",
                        "example": "success"
                    },
                    "success": {
                        "summary": "This optional object is included only if the `result` value is `success`",
                        "type": "object",
                        "properties": {
                            "transcription": {
                                "summary": "The transcription provided by the voice server",
                                "type": "string",
                                "example": "Comedy Central"
                            }
                        }
                    },
                    "error": {
                        "summary": "This optional object is included only if the `result` value is `error`",
                        "type": "object",
                        "properties": {
                            "protocolErrorCode": {
                                "summary": "The return code from the protocol used to communicate with the server (HTTP, WSS, and so on)",
                                "type": "integer",
                                "example": 200
                            },
                            "protocolLibraryErrorCode": {
                                "summary": "The return code from the library that was used to connect to the server (CURL, Nopoll, and so on)",
                                "type": "string",
                                "example": 0
                            },
                            "serverErrorCode": {
                                "summary": "The return code from the voice server",
                                "type": "integer",
                                "example": 1
                            },
                            "serverErrorString": {
                                "summary": "The error string from the voice server",
                                "type": "string",
                                "example": "Error"
                            },
                            "internalErrorCode": {
                                "summary": "The return code from the underlying RDK stack",
                                "type": "integer",
                                "example": 0
                            }
                        },
                        "required": [ ]
                    },
                    "abort": {
                        "summary": "This optional object is included only if the `result` value is `abort`",
                        "type": "object",
                        "properties": {
                            "reason": {
                                "summary": "The reason code that identifies why the session was aborted: `0` - Busy, `1` - Server Not Ready, `2` - Audio Format Error, `3` - General Failure, `4` - Voice Disabled, `5` - Device Update, `6` - Missing Authentication Data (that is, No Device ID, SAT, and so on), `7` - New Session, `8` - Controller ID Invalid, `9` - Application Restart",
                                "type": "integer",
                                "enum": [
                                    0,
                                    1,
                                    2,
                                    3,
                                    4,
                                    5,
                                    6,
                                    7,
                                    8,
                                    9
                                ],
                                "example": 1
                            }
                        }
                    },
                    "shortUtterance": {
                        "summary": "This optional object is included only if the `result` value is `abort`",
                        "type": "object",
                        "properties": {
                            "reason": {
                                "summary": "The reason code that identifies why the session was aborted: `0` - End of Stream (Mic Key Released / EOS detected), `1` - First Packet Timeout, `2` - Inter-packet Timeout, `3` - Max Utterance Length, `4` - Adjacent Key Press, `5` - Other Key Press, `6` - Other / Unknown",
                                "type": "integer",
                                "enum": [
                                    0,
                                    1,
                                    2,
                                    3,
                                    4,
                                    5,
                                    6
                                ],
                                "example": 1
                            }
                        }
                    }
                },
                "required": [
                    "remoteId",
                    "sessionId",
                    "reason"
                ]
            }
        },
        "onStreamBegin": {
            "summary": "Triggered when a device starts streaming voice data to the RDK. This event is optional, and will most likely be used for follow up sessions.",
            "params": {
                "type": "object",
                "properties": {
                    "remoteId": {
                        "$ref": "#/definitions/remoteId"
                    },
                    "sessionId": {
                        "$ref": "#/definitions/sessionId"
                    }
                },
                "required": [
                    "remoteId",
                    "sessionId"
                ]
            }
        },
        "onStreamEnd": {
            "summary": "Triggered when the device has stopped streaming audio",
            "params": {
                "type": "object",
                "properties": {
                    "remoteId": {
                        "$ref": "#/definitions/remoteId"
                    },
                    "sessionId": {
                        "$ref": "#/definitions/sessionId"
                    },
                    "reason": {
                        "summary": "The reason code for why the device stopped streaming audio: `0` - End of Stream (Mic Key Released / EOS detected), `1` - First Packet Timeout, `2` - Inter-packet Timeout, `3` - Max Utterance Length, `4` - Adjacent Key Press, `5`- Other Key Press, `6` - Other / Unknown",
                        "type": "integer",
                        "enum": [
                            0,
                            1,
                            2,
                            3,
                            4,
                            5,
                            6
                        ],
                        "example": 0
                    }
                },
                "required": [
                    "remoteId",
                    "sessionId",
                    "reason"
                ]
            }
        }
    }
}
